name: Release template
on:
  release:
    types: # This configuration does not affect the page_build event above
      - created
      - published
      - edited
      - released
      - prereleased

jobs:
  ChangeReleaseBody:
    runs-on: ubuntu-latest
    steps:
      - name: get version
        id: get_version
        run: |
          echo ::set-output name=VERSION::${GITHUB_REF/refs\/tags\//}
      - name: update release
        id: update_release
        uses: tubone24/update_release@v1.0
        env:
          GITHUB_TOKEN: ${{ github.token }}
        with:
          body: |
            To install on your machine download the installer below.

            On **WINDOWS** you should download `EyeCommander-x.x.x.Setup.exe` file.

            ## System Requirements

            EyeCommander is compatible with all modern versions of Windows, its been tested on Windows 10 and up.

            You **MUST** grant Administrator rights to EyeCommander when prompted.

            EyeCommander is uses a lot of CPU power to run, this is due to the fact that every frame has to be analysed by a machine learning model to extract all of your facial features.

            EyeCommander shows a 'frames per second' counter in the top left hand corner of the video feed. The higher the number of frames per second the more responsive and accurate the blink detection will be. The highest you will get is 30 frames per second and anything lower than 5 frames per second will be too low to work at all. You can run EyeCommander on GridPad devices but we have found that they get fairly low frame rates. EyeCommander still works at a low frame rate, however it will be less accurate and responsive but you might find its still usable for your use case.

            From our experience we have had the best success with Surface Pro tablets. They have enough processing power to run EyeCommander easily at 30 frames per second and work for our clients needs.
