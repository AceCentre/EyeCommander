{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 100\n",
    "img_width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20151 files belonging to 5 classes.\n",
      "Using 16121 files for training.\n",
      "Found 20151 files belonging to 5 classes.\n",
      "Using 4030 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  '/Users/danielkashkett/Desktop/EyeProject/data/eye_imgs/',\n",
    "  validation_split=0.2,\n",
    "    color_mode=\"grayscale\",\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  '/Users/danielkashkett/Desktop/EyeProject/data/eye_imgs/',\n",
    "  validation_split=0.2,\n",
    "  color_mode=\"grayscale\",\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['center', 'down', 'left', 'right', 'up']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(): \n",
    "    num_classes = 5\n",
    "\n",
    "    model = Sequential([\n",
    "      layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 1)),\n",
    "      layers.Conv2D(16, 1, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(32, 1, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(64, 1, padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Dropout(0.2),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(num_classes)\n",
    "    ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam')\n",
    "    \n",
    "    model.compile(optimizer=\"adam\", \n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "504/504 [==============================] - 35s 70ms/step - loss: 0.8329 - accuracy: 0.6954 - val_loss: 0.4422 - val_accuracy: 0.8600\n",
      "Epoch 2/5\n",
      "504/504 [==============================] - 34s 68ms/step - loss: 0.3898 - accuracy: 0.8764 - val_loss: 0.3317 - val_accuracy: 0.9025\n",
      "Epoch 3/5\n",
      "504/504 [==============================] - 36s 71ms/step - loss: 0.2904 - accuracy: 0.9059 - val_loss: 0.2822 - val_accuracy: 0.9062\n",
      "Epoch 4/5\n",
      "504/504 [==============================] - 35s 70ms/step - loss: 0.2435 - accuracy: 0.9189 - val_loss: 0.2367 - val_accuracy: 0.9191\n",
      "Epoch 5/5\n",
      "504/504 [==============================] - 36s 72ms/step - loss: 0.2114 - accuracy: 0.9265 - val_loss: 0.2289 - val_accuracy: 0.9223\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "epochs = 5\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "504/504 [==============================] - 32s 63ms/step - loss: 0.1904 - accuracy: 0.9337 - val_loss: 0.2094 - val_accuracy: 0.9288\n",
      "Epoch 2/5\n",
      "504/504 [==============================] - 36s 72ms/step - loss: 0.1746 - accuracy: 0.9378 - val_loss: 0.2042 - val_accuracy: 0.9305\n",
      "Epoch 3/5\n",
      "504/504 [==============================] - 34s 67ms/step - loss: 0.1595 - accuracy: 0.9440 - val_loss: 0.1998 - val_accuracy: 0.9330\n",
      "Epoch 4/5\n",
      "504/504 [==============================] - 35s 69ms/step - loss: 0.1541 - accuracy: 0.9448 - val_loss: 0.2024 - val_accuracy: 0.9355\n",
      "Epoch 5/5\n",
      "504/504 [==============================] - 34s 68ms/step - loss: 0.1450 - accuracy: 0.9482 - val_loss: 0.1795 - val_accuracy: 0.9402\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "504/504 [==============================] - 32s 63ms/step - loss: 0.1363 - accuracy: 0.9506 - val_loss: 0.1895 - val_accuracy: 0.9380\n",
      "Epoch 2/2\n",
      "504/504 [==============================] - 36s 71ms/step - loss: 0.1280 - accuracy: 0.9548 - val_loss: 0.1776 - val_accuracy: 0.9402\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./Models/jupiter1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./Models/jupiter1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('./Models/jupiter1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('../data/eye_imgs/right/a1.jpg' ,cv2.IMREAD_UNCHANGED)\n",
    "img2 = cv2.imread('../data/eye_imgs/left/a10.jpg' ,cv2.IMREAD_UNCHANGED)\n",
    "# img = img.reshape((100,100,1))\n",
    "# img = np.expand_dims(img,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_both(left = img1, right = img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_prediction():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.expand_dims(img1,0)\n",
    "img2 = np.expand_dims(img2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.concatenate((img1,img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 100, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.0141094, -0.907617 ,  3.9984462, -2.9328032,  1.9947188],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_both(left, right):\n",
    "    img1 = np.expand_dims(left,0)\n",
    "    img2 = np.expand_dims(right,0)\n",
    "    concat = np.concatenate((img1,img2))\n",
    "    classes = model.predict_classes(concat)\n",
    "    if classes[0] == classes[1]:\n",
    "        return classes[0]\n",
    "    else:\n",
    "        pred = model.predict(concat)\n",
    "        a = (pred[0].argmax(), pred[0].max())\n",
    "        b = (pred[1].argmax(), pred[1].max())\n",
    "        if a[1] > b[1]:\n",
    "            return a[0]\n",
    "        else:\n",
    "            return b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frame(self, eye_img):\n",
    "    img = eye_img.copy()\n",
    "    batch = np.expand_dims(img,0)\n",
    "    prediction = self.model.predict_classes(batch)[0]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['center', 'down', 'left', 'right', 'up']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe44183d8b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(img)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
