{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_classes = 5\n",
    "img_height = 50\n",
    "img_width = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15252 files belonging to 5 classes.\n",
      "Using 13727 files for training.\n",
      "Found 15252 files belonging to 5 classes.\n",
      "Using 1525 files for validation.\n",
      "Found 1372 files belonging to 5 classes.\n",
      "['center', 'down', 'left', 'right', 'up']\n"
     ]
    }
   ],
   "source": [
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  '../../../data/raw/eye_frames/50_50/',\n",
    "  validation_split=0.1,\n",
    "    color_mode=\"grayscale\",\n",
    "    label_mode='int',\n",
    "  subset=\"training\",\n",
    "    shuffle=True,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "dev = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  '../../../data/raw/eye_frames/50_50/',\n",
    "  validation_split=0.1,\n",
    "  color_mode=\"grayscale\",\n",
    "    label_mode='int',\n",
    "    shuffle=True,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  '../../../data/raw/eye_frames/testing_50_50/',\n",
    "  color_mode=\"grayscale\",\n",
    "    label_mode='int',\n",
    "    shuffle=True,\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"jupiter3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 50, 50, 1)]       0         \n",
      "_________________________________________________________________\n",
      "rescaling_3 (Rescaling)      (None, 50, 50, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 50, 50, 32)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 25, 25, 64)        2112      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 128)       8320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,191,685\n",
      "Trainable params: 1,191,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = keras.Input(shape=(img_height, img_width, 1))\n",
    "x = keras.layers.experimental.preprocessing.Rescaling(1./255)(input_layer)\n",
    "x = keras.layers.Conv2D(32, 1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D()(x)\n",
    "# x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Conv2D(64, 1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D()(x)\n",
    "# x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Conv2D(128, 1, padding='same', activation='relu')(x)\n",
    "x = keras.layers.MaxPooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "# x = keras.layers.Dense(32, activation='relu')(x)\n",
    "output_layer = keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=input_layer, outputs=output_layer, name=\"jupiter3\")\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam')\n",
    "# opt = tf.keras.optimizers.SGD(lr=0.0001, momentum=0.9)\n",
    "# model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "model.compile(optimizer=opt, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "   \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('./best_model_aug.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "callbacks = [es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 1.1927 - accuracy: 0.7161\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.89770, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 1.1927 - accuracy: 0.7161 - val_loss: 1.0109 - val_accuracy: 0.8977\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 1.0062 - accuracy: 0.9014\n",
      "Epoch 00002: val_accuracy improved from 0.89770 to 0.92393, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 15s 34ms/step - loss: 1.0062 - accuracy: 0.9014 - val_loss: 0.9837 - val_accuracy: 0.9239\n",
      "Epoch 3/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9887 - accuracy: 0.9170\n",
      "Epoch 00003: val_accuracy improved from 0.92393 to 0.93574, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 15s 34ms/step - loss: 0.9885 - accuracy: 0.9172 - val_loss: 0.9719 - val_accuracy: 0.9357\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9671 - accuracy: 0.9392\n",
      "Epoch 00004: val_accuracy improved from 0.93574 to 0.94295, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 15s 34ms/step - loss: 0.9671 - accuracy: 0.9392 - val_loss: 0.9604 - val_accuracy: 0.9430\n",
      "Epoch 5/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9554 - accuracy: 0.9504\n",
      "Epoch 00005: val_accuracy improved from 0.94295 to 0.96197, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9552 - accuracy: 0.9505 - val_loss: 0.9444 - val_accuracy: 0.9620\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9493 - accuracy: 0.9559\n",
      "Epoch 00006: val_accuracy did not improve from 0.96197\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9493 - accuracy: 0.9559 - val_loss: 0.9456 - val_accuracy: 0.9593\n",
      "Epoch 7/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9428 - accuracy: 0.9621\n",
      "Epoch 00007: val_accuracy improved from 0.96197 to 0.96393, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9428 - accuracy: 0.9621 - val_loss: 0.9409 - val_accuracy: 0.9639\n",
      "Epoch 8/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9380 - accuracy: 0.9675\n",
      "Epoch 00008: val_accuracy improved from 0.96393 to 0.96984, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9380 - accuracy: 0.9675 - val_loss: 0.9338 - val_accuracy: 0.9698\n",
      "Epoch 9/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9360 - accuracy: 0.9685\n",
      "Epoch 00009: val_accuracy improved from 0.96984 to 0.97115, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 16s 37ms/step - loss: 0.9360 - accuracy: 0.9685 - val_loss: 0.9335 - val_accuracy: 0.9711\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9311 - accuracy: 0.9742\n",
      "Epoch 00010: val_accuracy improved from 0.97115 to 0.97443, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 18s 42ms/step - loss: 0.9311 - accuracy: 0.9742 - val_loss: 0.9307 - val_accuracy: 0.9744\n",
      "Epoch 11/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9338 - accuracy: 0.9711\n",
      "Epoch 00011: val_accuracy improved from 0.97443 to 0.97967, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 19s 44ms/step - loss: 0.9339 - accuracy: 0.9710 - val_loss: 0.9260 - val_accuracy: 0.9797\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9315 - accuracy: 0.9738\n",
      "Epoch 00012: val_accuracy did not improve from 0.97967\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9315 - accuracy: 0.9738 - val_loss: 0.9404 - val_accuracy: 0.9659\n",
      "Epoch 13/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9306 - accuracy: 0.9744\n",
      "Epoch 00013: val_accuracy did not improve from 0.97967\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9306 - accuracy: 0.9744 - val_loss: 0.9307 - val_accuracy: 0.9738\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9279 - accuracy: 0.9772\n",
      "Epoch 00014: val_accuracy did not improve from 0.97967\n",
      "429/429 [==============================] - 15s 34ms/step - loss: 0.9279 - accuracy: 0.9772 - val_loss: 0.9284 - val_accuracy: 0.9764\n",
      "Epoch 15/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9281 - accuracy: 0.9769\n",
      "Epoch 00015: val_accuracy did not improve from 0.97967\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9282 - accuracy: 0.9768 - val_loss: 0.9329 - val_accuracy: 0.9718\n",
      "Epoch 16/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9284 - accuracy: 0.9767\n",
      "Epoch 00016: val_accuracy did not improve from 0.97967\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9285 - accuracy: 0.9766 - val_loss: 0.9293 - val_accuracy: 0.9757\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9251 - accuracy: 0.9797\n",
      "Epoch 00017: val_accuracy did not improve from 0.97967\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9251 - accuracy: 0.9797 - val_loss: 0.9262 - val_accuracy: 0.9784\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9277 - accuracy: 0.9773\n",
      "Epoch 00018: val_accuracy improved from 0.97967 to 0.98361, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9277 - accuracy: 0.9773 - val_loss: 0.9212 - val_accuracy: 0.9836\n",
      "Epoch 19/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9251 - accuracy: 0.9793\n",
      "Epoch 00019: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9250 - accuracy: 0.9793 - val_loss: 0.9226 - val_accuracy: 0.9816\n",
      "Epoch 20/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9260 - accuracy: 0.9793\n",
      "Epoch 00020: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9260 - accuracy: 0.9792 - val_loss: 0.9243 - val_accuracy: 0.9810\n",
      "Epoch 21/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9233 - accuracy: 0.9815\n",
      "Epoch 00021: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9235 - accuracy: 0.9814 - val_loss: 0.9251 - val_accuracy: 0.9803\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9242 - accuracy: 0.9808\n",
      "Epoch 00022: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9242 - accuracy: 0.9808 - val_loss: 0.9304 - val_accuracy: 0.9738\n",
      "Epoch 23/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9258 - accuracy: 0.9789\n",
      "Epoch 00023: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9257 - accuracy: 0.9789 - val_loss: 0.9214 - val_accuracy: 0.9836\n",
      "Epoch 24/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9242 - accuracy: 0.9807 E\n",
      "Epoch 00024: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9241 - accuracy: 0.9808 - val_loss: 0.9212 - val_accuracy: 0.9836\n",
      "Epoch 25/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9244 - accuracy: 0.9807\n",
      "Epoch 00025: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9244 - accuracy: 0.9806 - val_loss: 0.9217 - val_accuracy: 0.9836\n",
      "Epoch 26/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9232 - accuracy: 0.9815\n",
      "Epoch 00026: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9232 - accuracy: 0.9815 - val_loss: 0.9230 - val_accuracy: 0.9810\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9224 - accuracy: 0.9826\n",
      "Epoch 00027: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9224 - accuracy: 0.9826 - val_loss: 0.9238 - val_accuracy: 0.9810\n",
      "Epoch 28/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9250 - accuracy: 0.9796\n",
      "Epoch 00028: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9250 - accuracy: 0.9797 - val_loss: 0.9382 - val_accuracy: 0.9666\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9239 - accuracy: 0.9805\n",
      "Epoch 00029: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 16s 37ms/step - loss: 0.9239 - accuracy: 0.9805 - val_loss: 0.9221 - val_accuracy: 0.9823\n",
      "Epoch 30/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9218 - accuracy: 0.9827\n",
      "Epoch 00030: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 16s 36ms/step - loss: 0.9219 - accuracy: 0.9827 - val_loss: 0.9215 - val_accuracy: 0.9830\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9210 - accuracy: 0.9839\n",
      "Epoch 00031: val_accuracy did not improve from 0.98361\n",
      "429/429 [==============================] - 15s 36ms/step - loss: 0.9210 - accuracy: 0.9839 - val_loss: 0.9208 - val_accuracy: 0.9836\n",
      "Epoch 32/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9217 - accuracy: 0.9828\n",
      "Epoch 00032: val_accuracy improved from 0.98361 to 0.98426, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 16s 38ms/step - loss: 0.9217 - accuracy: 0.9828 - val_loss: 0.9211 - val_accuracy: 0.9843\n",
      "Epoch 33/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9229 - accuracy: 0.9818\n",
      "Epoch 00033: val_accuracy did not improve from 0.98426\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9229 - accuracy: 0.9819 - val_loss: 0.9238 - val_accuracy: 0.9810\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9231 - accuracy: 0.9819\n",
      "Epoch 00034: val_accuracy did not improve from 0.98426\n",
      "429/429 [==============================] - 15s 36ms/step - loss: 0.9231 - accuracy: 0.9819 - val_loss: 0.9257 - val_accuracy: 0.9790\n",
      "Epoch 35/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9243 - accuracy: 0.9804\n",
      "Epoch 00035: val_accuracy did not improve from 0.98426\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9244 - accuracy: 0.9803 - val_loss: 0.9215 - val_accuracy: 0.9830\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9237 - accuracy: 0.9811\n",
      "Epoch 00036: val_accuracy did not improve from 0.98426\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9237 - accuracy: 0.9811 - val_loss: 0.9218 - val_accuracy: 0.9823\n",
      "Epoch 37/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9200 - accuracy: 0.9847\n",
      "Epoch 00037: val_accuracy improved from 0.98426 to 0.98492, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9200 - accuracy: 0.9848 - val_loss: 0.9206 - val_accuracy: 0.9849\n",
      "Epoch 38/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9219 - accuracy: 0.9828\n",
      "Epoch 00038: val_accuracy did not improve from 0.98492\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9220 - accuracy: 0.9827 - val_loss: 0.9226 - val_accuracy: 0.9830\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9238 - accuracy: 0.9811\n",
      "Epoch 00039: val_accuracy did not improve from 0.98492\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9238 - accuracy: 0.9811 - val_loss: 0.9250 - val_accuracy: 0.9797\n",
      "Epoch 40/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9228 - accuracy: 0.9819\n",
      "Epoch 00040: val_accuracy improved from 0.98492 to 0.98557, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9227 - accuracy: 0.9819 - val_loss: 0.9189 - val_accuracy: 0.9856\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9224 - accuracy: 0.9822\n",
      "Epoch 00041: val_accuracy did not improve from 0.98557\n",
      "429/429 [==============================] - 15s 34ms/step - loss: 0.9224 - accuracy: 0.9822 - val_loss: 0.9361 - val_accuracy: 0.9685\n",
      "Epoch 42/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9246 - accuracy: 0.9799\n",
      "Epoch 00042: val_accuracy did not improve from 0.98557\n",
      "429/429 [==============================] - 16s 37ms/step - loss: 0.9246 - accuracy: 0.9800 - val_loss: 0.9254 - val_accuracy: 0.9784\n",
      "Epoch 43/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9208 - accuracy: 0.9838\n",
      "Epoch 00043: val_accuracy did not improve from 0.98557\n",
      "429/429 [==============================] - 21s 48ms/step - loss: 0.9209 - accuracy: 0.9838 - val_loss: 0.9234 - val_accuracy: 0.9810\n",
      "Epoch 44/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9218 - accuracy: 0.9827\n",
      "Epoch 00044: val_accuracy did not improve from 0.98557\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9218 - accuracy: 0.9827 - val_loss: 0.9227 - val_accuracy: 0.9816\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9215 - accuracy: 0.9833\n",
      "Epoch 00045: val_accuracy did not improve from 0.98557\n",
      "429/429 [==============================] - 16s 36ms/step - loss: 0.9215 - accuracy: 0.9833 - val_loss: 0.9212 - val_accuracy: 0.9836\n",
      "Epoch 46/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9220 - accuracy: 0.9830\n",
      "Epoch 00046: val_accuracy did not improve from 0.98557\n",
      "429/429 [==============================] - 17s 40ms/step - loss: 0.9220 - accuracy: 0.9830 - val_loss: 0.9202 - val_accuracy: 0.9849\n",
      "Epoch 47/50\n",
      "428/429 [============================>.] - ETA: 0s - loss: 0.9222 - accuracy: 0.9827\n",
      "Epoch 00047: val_accuracy improved from 0.98557 to 0.98623, saving model to ./best_model_aug.h5\n",
      "429/429 [==============================] - 16s 36ms/step - loss: 0.9221 - accuracy: 0.9827 - val_loss: 0.9180 - val_accuracy: 0.9862\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9209 - accuracy: 0.9839\n",
      "Epoch 00048: val_accuracy did not improve from 0.98623\n",
      "429/429 [==============================] - 16s 37ms/step - loss: 0.9209 - accuracy: 0.9839 - val_loss: 0.9202 - val_accuracy: 0.9849\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9223 - accuracy: 0.9824\n",
      "Epoch 00049: val_accuracy did not improve from 0.98623\n",
      "429/429 [==============================] - 15s 35ms/step - loss: 0.9223 - accuracy: 0.9824 - val_loss: 0.9217 - val_accuracy: 0.9823\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.9192 - accuracy: 0.9856\n",
      "Epoch 00050: val_accuracy did not improve from 0.98623\n",
      "429/429 [==============================] - 16s 38ms/step - loss: 0.9192 - accuracy: 0.9856 - val_loss: 0.9199 - val_accuracy: 0.9849\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train,\n",
    "  validation_data=dev,\n",
    "  epochs=epochs, \n",
    "  batch_size =batch_size,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcb009a4670>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_history.val_accuracy.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(arr):\n",
    "    for idx in range(len(arr)):\n",
    "        img = arr[idx]\n",
    "        img = np.array(tf.image.random_brightness(img,max_delta=0.3))\n",
    "        while (img.mean() > 210) or (img.mean() < 50):\n",
    "            img = np.array(tf.image.random_brightness(img,max_delta=0.3))\n",
    "        arr[idx] = img\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 356, 1: 258, 2: 268, 3: 414, 4: 76}\n"
     ]
    }
   ],
   "source": [
    "path = '../../../data/raw/eye_frames/testing_50_50/'\n",
    "d = {}\n",
    "for idx, l in enumerate(['center', 'down', 'left', 'right', 'up']):\n",
    "    subpath = os.path.join(path, l)\n",
    "    files = glob.glob(subpath + '/*.jpg')\n",
    "    data = []\n",
    "    for f in files:\n",
    "        img = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n",
    "        data.append(img)\n",
    "    d[idx] = np.array(data)\n",
    "shapes = {key:val.shape[0] for key,val in d.items()}\n",
    "max_size = max(shapes.values())\n",
    "print(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 414, 1: 414, 2: 414, 3: 414, 4: 414}\n"
     ]
    }
   ],
   "source": [
    "for key, val in shapes.items():\n",
    "    diff = max_size - val\n",
    "    if diff <= 0:\n",
    "        continue\n",
    "    else:\n",
    "        smpl_idxs = np.random.randint(0, val-1, size=diff)\n",
    "        samples = augment(d[key][smpl_idxs])\n",
    "        d[key] = np.concatenate([d[key],samples])\n",
    "shapes = {key:val.shape[0] for key,val in d.items()}\n",
    "print(shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, val in shapes.items():\n",
    "#     diff = max_size - val\n",
    "#     if diff <= 0:\n",
    "#         continue\n",
    "#     else:\n",
    "#         smpl_idxs = np.random.randint(0, val-1, size=diff)\n",
    "#         samples = d[key][smpl_idxs]\n",
    "#         d[key] = np.concatenate([d[key],samples])\n",
    "# shapes = {key:val.shape[0] for key,val in d.items()}\n",
    "# print(shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 828, 1: 828, 2: 828, 3: 828, 4: 828}\n"
     ]
    }
   ],
   "source": [
    "# double up\n",
    "d[0] = np.concatenate([d[0],d[0]])\n",
    "d[1] = np.concatenate([d[1],d[1]])\n",
    "d[2] = np.concatenate([d[2],d[2]])\n",
    "d[3] = np.concatenate([d[3],d[3]])\n",
    "d[4] = np.concatenate([d[4],d[4]])\n",
    "shapes = {key:val.shape[0] for key,val in d.items()}\n",
    "print(shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "for key, val in d.items():\n",
    "    images.extend(list(val))\n",
    "    labels.extend([key]*len(val))\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 1s 11ms/step - loss: 1.4045 - accuracy: 0.2164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.40449857711792, 0.2164251208305359]"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jupiter = tf.keras.models.load_model('../models/jupiter3.h5')\n",
    "jupiter.evaluate(x=images,y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(jupiter.layers)):\n",
    "    jupiter.layers[i].trainable = False\n",
    "jupiter.layers[-1].trainable = True\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam')\n",
    "\n",
    "jupiter.compile(optimizer=opt, \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('./tuned.h5', monitor='accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "callbacks = [es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "4139/4140 [============================>.] - ETA: 0s - loss: 1.2875 - accuracy: 0.6125\n",
      "Epoch 00001: accuracy improved from -inf to 0.61256, saving model to ./tuned.h5\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.2874 - accuracy: 0.6126\n",
      "Epoch 2/20\n",
      "4122/4140 [============================>.] - ETA: 0s - loss: 1.2605 - accuracy: 0.6405\n",
      "Epoch 00002: accuracy improved from 0.61256 to 0.64034, saving model to ./tuned.h5\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.2606 - accuracy: 0.6403\n",
      "Epoch 3/20\n",
      "4126/4140 [============================>.] - ETA: 0s - loss: 1.2378 - accuracy: 0.6653\n",
      "Epoch 00003: accuracy improved from 0.64034 to 0.66570, saving model to ./tuned.h5\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.2374 - accuracy: 0.6657\n",
      "Epoch 4/20\n",
      "4105/4140 [============================>.] - ETA: 0s - loss: 1.2394 - accuracy: 0.6636\n",
      "Epoch 00004: accuracy did not improve from 0.66570\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.2399 - accuracy: 0.6630\n",
      "Epoch 5/20\n",
      "4120/4140 [============================>.] - ETA: 0s - loss: 1.2342 - accuracy: 0.6677\n",
      "Epoch 00005: accuracy improved from 0.66570 to 0.66787, saving model to ./tuned.h5\n",
      "4140/4140 [==============================] - 5s 1ms/step - loss: 1.2340 - accuracy: 0.6679\n",
      "Epoch 6/20\n",
      "4107/4140 [============================>.] - ETA: 0s - loss: 1.1992 - accuracy: 0.7039\n",
      "Epoch 00006: accuracy improved from 0.66787 to 0.70411, saving model to ./tuned.h5\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.1991 - accuracy: 0.7041\n",
      "Epoch 7/20\n",
      "4113/4140 [============================>.] - ETA: 0s - loss: 1.2018 - accuracy: 0.7017\n",
      "Epoch 00007: accuracy did not improve from 0.70411\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.2016 - accuracy: 0.7017\n",
      "Epoch 8/20\n",
      "4112/4140 [============================>.] - ETA: 0s - loss: 1.2025 - accuracy: 0.7004\n",
      "Epoch 00008: accuracy did not improve from 0.70411\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.2023 - accuracy: 0.7005\n",
      "Epoch 9/20\n",
      "4106/4140 [============================>.] - ETA: 0s - loss: 1.2064 - accuracy: 0.6980\n",
      "Epoch 00009: accuracy did not improve from 0.70411\n",
      "4140/4140 [==============================] - 4s 995us/step - loss: 1.2054 - accuracy: 0.6990\n",
      "Epoch 10/20\n",
      "4111/4140 [============================>.] - ETA: 0s - loss: 1.2071 - accuracy: 0.6962\n",
      "Epoch 00010: accuracy did not improve from 0.70411\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.2073 - accuracy: 0.6959\n",
      "Epoch 11/20\n",
      "4105/4140 [============================>.] - ETA: 0s - loss: 1.2052 - accuracy: 0.6982\n",
      "Epoch 00011: accuracy did not improve from 0.70411\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.2061 - accuracy: 0.6973\n",
      "Epoch 12/20\n",
      "4113/4140 [============================>.] - ETA: 0s - loss: 1.1921 - accuracy: 0.7114\n",
      "Epoch 00012: accuracy improved from 0.70411 to 0.71184, saving model to ./tuned.h5\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.1917 - accuracy: 0.7118\n",
      "Epoch 13/20\n",
      "4128/4140 [============================>.] - ETA: 0s - loss: 1.2003 - accuracy: 0.7025\n",
      "Epoch 00013: accuracy did not improve from 0.71184\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.2002 - accuracy: 0.7024\n",
      "Epoch 14/20\n",
      "4101/4140 [============================>.] - ETA: 0s - loss: 1.1952 - accuracy: 0.7074\n",
      "Epoch 00014: accuracy did not improve from 0.71184\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.1948 - accuracy: 0.7077\n",
      "Epoch 15/20\n",
      "4115/4140 [============================>.] - ETA: 0s - loss: 1.1781 - accuracy: 0.7247\n",
      "Epoch 00015: accuracy improved from 0.71184 to 0.72440, saving model to ./tuned.h5\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.1783 - accuracy: 0.7244\n",
      "Epoch 16/20\n",
      "4139/4140 [============================>.] - ETA: 0s - loss: 1.1870 - accuracy: 0.7154\n",
      "Epoch 00016: accuracy did not improve from 0.72440\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.1869 - accuracy: 0.7155\n",
      "Epoch 17/20\n",
      "4108/4140 [============================>.] - ETA: 0s - loss: 1.1803 - accuracy: 0.7215\n",
      "Epoch 00017: accuracy did not improve from 0.72440\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.1803 - accuracy: 0.7215\n",
      "Epoch 18/20\n",
      "4119/4140 [============================>.] - ETA: 0s - loss: 1.1818 - accuracy: 0.7223\n",
      "Epoch 00018: accuracy did not improve from 0.72440\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.1811 - accuracy: 0.7229\n",
      "Epoch 19/20\n",
      "4101/4140 [============================>.] - ETA: 0s - loss: 1.1803 - accuracy: 0.7232\n",
      "Epoch 00019: accuracy did not improve from 0.72440\n",
      "4140/4140 [==============================] - 4s 1ms/step - loss: 1.1798 - accuracy: 0.7237\n",
      "Epoch 20/20\n",
      "4129/4140 [============================>.] - ETA: 0s - loss: 1.1882 - accuracy: 0.7145\n",
      "Epoch 00020: accuracy did not improve from 0.72440\n",
      "4140/4140 [==============================] - 5s 1ms/step - loss: 1.1877 - accuracy: 0.7150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcaf3f15640>"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "retrain_history = jupiter.fit(\n",
    "x= images,\n",
    "    y=labels,\n",
    "  epochs=20, \n",
    "  batch_size =1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "train_history = pd.DataFrame(history.history)\n",
    "train_history.loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 1s 11ms/step - loss: 1.1863 - accuracy: 0.7179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1862579584121704, 0.7178744077682495]"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jupiter.evaluate(x=images,y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = jupiter.predict(images)\n",
    "predictions =[i.argmax() for i in predictions]\n",
    "report = classification_report(labels,predictions, output_dict=True)\n",
    "report= pd.DataFrame(report).transpose()\n",
    "scores = report['f1-score'].iloc[0:5]\n",
    "scores = {int(i):j for i,j in zip(scores.index,scores.values)}\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "824/828 [============================>.] - ETA: 0s - loss: 1.4362 - accuracy: 0.4660\n",
      "Epoch 00001: accuracy did not improve from 0.72440\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 1.4348 - accuracy: 0.4674\n",
      "Epoch 2/20\n",
      "801/828 [============================>.] - ETA: 0s - loss: 1.3825 - accuracy: 0.5218\n",
      "Epoch 00002: accuracy did not improve from 0.72440\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 1.3777 - accuracy: 0.5266\n",
      "Epoch 3/20\n",
      "800/828 [===========================>..] - ETA: 0s - loss: 1.3513 - accuracy: 0.5525\n",
      "Epoch 00003: accuracy did not improve from 0.72440\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 1.3458 - accuracy: 0.5580\n",
      "Epoch 4/20\n",
      "784/828 [===========================>..] - ETA: 0s - loss: 1.1369 - accuracy: 0.7666\n",
      "Epoch 00004: accuracy improved from 0.72440 to 0.76932, saving model to ./tuned.h5\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 1.1341 - accuracy: 0.7693\n",
      "Epoch 5/20\n",
      "797/828 [===========================>..] - ETA: 0s - loss: 1.0031 - accuracy: 0.9009\n",
      "Epoch 00005: accuracy improved from 0.76932 to 0.90217, saving model to ./tuned.h5\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 1.0018 - accuracy: 0.9022\n",
      "Epoch 6/20\n",
      "786/828 [===========================>..] - ETA: 0s - loss: 0.9597 - accuracy: 0.9440\n",
      "Epoch 00006: accuracy improved from 0.90217 to 0.94565, saving model to ./tuned.h5\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9582 - accuracy: 0.9457\n",
      "Epoch 7/20\n",
      "823/828 [============================>.] - ETA: 0s - loss: 0.9365 - accuracy: 0.9684\n",
      "Epoch 00007: accuracy improved from 0.94565 to 0.96860, saving model to ./tuned.h5\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9363 - accuracy: 0.9686\n",
      "Epoch 8/20\n",
      "817/828 [============================>.] - ETA: 0s - loss: 0.9273 - accuracy: 0.9780\n",
      "Epoch 00008: accuracy improved from 0.96860 to 0.97705, saving model to ./tuned.h5\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9284 - accuracy: 0.9771\n",
      "Epoch 9/20\n",
      "818/828 [============================>.] - ETA: 0s - loss: 0.9114 - accuracy: 0.9927\n",
      "Epoch 00009: accuracy improved from 0.97705 to 0.99275, saving model to ./tuned.h5\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9113 - accuracy: 0.9928\n",
      "Epoch 10/20\n",
      "782/828 [===========================>..] - ETA: 0s - loss: 0.9074 - accuracy: 0.9974\n",
      "Epoch 00010: accuracy improved from 0.99275 to 0.99758, saving model to ./tuned.h5\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9073 - accuracy: 0.9976\n",
      "Epoch 11/20\n",
      "821/828 [============================>.] - ETA: 0s - loss: 0.9097 - accuracy: 0.9951\n",
      "Epoch 00011: accuracy did not improve from 0.99758\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9097 - accuracy: 0.9952\n",
      "Epoch 12/20\n",
      "816/828 [============================>.] - ETA: 0s - loss: 0.9073 - accuracy: 0.9975\n",
      "Epoch 00012: accuracy did not improve from 0.99758\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9085 - accuracy: 0.9964\n",
      "Epoch 13/20\n",
      "822/828 [============================>.] - ETA: 0s - loss: 0.9097 - accuracy: 0.9951\n",
      "Epoch 00013: accuracy did not improve from 0.99758\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9097 - accuracy: 0.9952\n",
      "Epoch 14/20\n",
      "814/828 [============================>.] - ETA: 0s - loss: 0.9110 - accuracy: 0.9939\n",
      "Epoch 00014: accuracy did not improve from 0.99758\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9109 - accuracy: 0.9940\n",
      "Epoch 15/20\n",
      "811/828 [============================>.] - ETA: 0s - loss: 0.9083 - accuracy: 0.9963\n",
      "Epoch 00015: accuracy did not improve from 0.99758\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9083 - accuracy: 0.9964\n",
      "Epoch 16/20\n",
      "800/828 [===========================>..] - ETA: 0s - loss: 0.9085 - accuracy: 0.9962\n",
      "Epoch 00016: accuracy did not improve from 0.99758\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9084 - accuracy: 0.9964\n",
      "Epoch 17/20\n",
      "826/828 [============================>.] - ETA: 0s - loss: 0.9082 - accuracy: 0.9964\n",
      "Epoch 00017: accuracy did not improve from 0.99758\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9082 - accuracy: 0.9964\n",
      "Epoch 18/20\n",
      "793/828 [===========================>..] - ETA: 0s - loss: 0.9064 - accuracy: 0.9987 ETA: 0s - loss: 0.9\n",
      "Epoch 00018: accuracy improved from 0.99758 to 0.99879, saving model to ./tuned.h5\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9063 - accuracy: 0.9988\n",
      "Epoch 19/20\n",
      "795/828 [===========================>..] - ETA: 0s - loss: 0.9073 - accuracy: 0.9975\n",
      "Epoch 00019: accuracy did not improve from 0.99879\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9072 - accuracy: 0.9976\n",
      "Epoch 20/20\n",
      "810/828 [============================>.] - ETA: 0s - loss: 0.9061 - accuracy: 0.9988\n",
      "Epoch 00020: accuracy did not improve from 0.99879\n",
      "828/828 [==============================] - 1s 1ms/step - loss: 0.9060 - accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "retrain_history = jupiter.fit(\n",
    "x= d[0],\n",
    "    y=np.array([0]*len(d[0])),\n",
    "  epochs=20, \n",
    "  batch_size =1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.3246268656716418, 1: 0.7130620985010706, 2: 0.9076517150395778, 3: 0.7360157016683024, 4: 0.7771556550951848}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.36990595611285265, 1: 0.004807692307692307, 2: 0.5479930191972078, 3: 0.0, 4: 0.014354066985645932}\n"
     ]
    }
   ],
   "source": [
    "predictions = jupiter.predict(images)\n",
    "predictions =[i.argmax() for i in predictions]\n",
    "report = classification_report(labels,predictions, output_dict=True)\n",
    "report= pd.DataFrame(report).transpose()\n",
    "scores = report['f1-score'].iloc[0:5]\n",
    "scores = {int(i):j for i,j in zip(scores.index,scores.values)}\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.21      0.32       828\n",
      "           1       0.64      0.80      0.71       828\n",
      "           2       1.00      0.83      0.91       828\n",
      "           3       0.62      0.91      0.74       828\n",
      "           4       0.72      0.84      0.78       828\n",
      "\n",
      "    accuracy                           0.72      4140\n",
      "   macro avg       0.74      0.72      0.69      4140\n",
      "weighted avg       0.74      0.72      0.69      4140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60       828\n",
      "           1       0.56      0.93      0.70       414\n",
      "           2       1.00      0.98      0.99       414\n",
      "           3       0.42      0.46      0.44       414\n",
      "           4       0.99      0.52      0.68       414\n",
      "\n",
      "    accuracy                           0.67      2484\n",
      "   macro avg       0.72      0.69      0.68      2484\n",
      "weighted avg       0.71      0.67      0.67      2484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.52      0.63      1780\n",
      "           1       0.71      0.92      0.81      1290\n",
      "           2       0.97      0.98      0.97      1340\n",
      "           3       0.76      0.91      0.83      2070\n",
      "           4       1.00      0.55      0.71       380\n",
      "\n",
      "    accuracy                           0.81      6860\n",
      "   macro avg       0.85      0.78      0.79      6860\n",
      "weighted avg       0.82      0.81      0.80      6860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['center', 'down', 'left', 'right', 'up']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4803206997084548"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 50, 50, 1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.models.load_model('./best_model_aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 1s 6ms/step - loss: 0.9311 - accuracy: 0.1825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9311159253120422, 0.18251365423202515]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(basepath):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for label in ['up','down','left','right','center']:\n",
    "        files = glob.glob(os.path.join(basepath,label) + '/*.jpg')\n",
    "        for f in files:\n",
    "            img = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n",
    "            img = img.reshape((50,50,1))\n",
    "#             img = np.expand_dims(img,0)\n",
    "            data.append(img)\n",
    "            labels.append(label)\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    print('loading complete.')\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading complete.\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset(basepath='../../../data/raw/eye_frames/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15252, 50, 50, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['center', 'down', 'left', 'right', 'up'], dtype='<U6')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.33, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
